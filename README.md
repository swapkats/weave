# ğŸ§µ Weave

**Build AI Agents in seconds, not months**

Weave is a declarative framework for building and composing interopable AI agents. Define what you want your agent to be in plain yaml and let weave worry about how to build and run the agent.

## âœ¨ Why Weave?

- âš¡ **Fast** - Go from idea to working agent workflow quickly
- ğŸ¯ **Simple** - Clean YAML configuration
- ğŸ”§ **Extensible** - Custom tools and plugins

## âœ¨ Key Features

- **Declarative YAML** - Define agents and workflows in configuration
- **Automatic Orchestration** - Smart dependency resolution and execution ordering
- **OpenAI-Compatible API** - Run agents as headless API endpoints compatible with OpenAI format
- **Tool Calling** - 9 built-in tools + custom tool support
- **Plugin System** - Built-in plugins for web search, data processing, formatting
- **MCP Integration** - Connect to Model Context Protocol servers
- **Prompt Engineering** - Organize prompts, skills, and knowledge bases

## ğŸ“¦ Installation

### From Source

```bash
git clone https://github.com/swapkats/weave.git
cd weave
pip install -e .
```

### Setup API Keys

Configure your LLM provider API keys using environment variables:

```bash
# Set API keys via environment
export OPENAI_API_KEY="your-key-here"
export ANTHROPIC_API_KEY="your-key-here"

# Optional: OpenRouter for multi-model access
export OPENROUTER_API_KEY="your-key-here"
```

Alternatively, API keys can be stored encrypted in `~/.agent/api_keys.yaml` using the APIKeyManager.

## ğŸš€ Quick Start

### 1. Initialize a Project

```bash
weave init
```

This creates a `.agent.yaml` file:

```yaml
version: "1.0"

agents:
  researcher:
    model: "gpt-4"
    tools: [web_search]
    outputs: "research_summary"

  writer:
    model: "claude-3-opus"
    inputs: "researcher"
    outputs: "draft_article"

weaves:
  content_pipeline:
    description: "Research and write content"
    agents: [researcher, writer]
```
### 2. Run Interactive Chat

```bash
# Chat with default model
weave run

# Chat with specific agent from config
weave run agent researcher
```

### 3. Run as OpenAI-Compatible API

Run your agent as a headless API server that's compatible with OpenAI's API format:

```bash
# Start API server
weave run agent researcher --openai-mode

# Custom host and port
weave run agent researcher --openai-mode --host 127.0.0.1 --port 3000
```

Use with any OpenAI-compatible client:

```python
from openai import OpenAI

client = OpenAI(base_url="http://localhost:8765/v1", api_key="dummy")
response = client.chat.completions.create(
    model="researcher",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

See [OPENAI_MODE.md](OPENAI_MODE.md) for detailed documentation.

### 4. Review Execution Plan

```bash
weave plan
```

Output:
```
ğŸ“Š Execution Plan: content_pipeline

Order  Agent       Model         Inputs
1      researcher  gpt-4         -
2      writer      claude-3-opus researcher

Execution graph:
  researcher â†’ writer

2 agents will be created
```

### 5. Apply Your Workflow

```bash
weave apply
```

## ğŸ› ï¸ Built-in Tools

Weave includes 9 production-ready tools:

**Math & Text:**
- `calculator` - Evaluate mathematical expressions
- `text_length` - Count characters, words, lines
- `string_formatter` - Template-based string formatting

**Data Processing:**
- `json_validator` - Validate and parse JSON
- `list_operations` - List operations (sort, filter, etc.)

**Web & HTTP:**
- `http_request` - Make HTTP requests (GET, POST, PUT, DELETE)
- `web_search` - Search the web (DuckDuckGo)

**File Operations:**
- `file_read` - Read file contents
- `file_write` - Write content to files
- `file_list` - List directory contents

### Using Tools

```yaml
agents:
  data_agent:
    model: "gpt-4"
    tools:
      - http_request
      - file_read
      - file_write
```

## ğŸ”Œ Plugins

Built-in plugins for extended functionality:

- **web_search** - Real web search via DuckDuckGo API
- **openrouter** - Unified LLM access (100+ models)
- **data_cleaner** - Clean and normalize data
- **json_parser** - Parse and validate JSON
- **markdown_formatter** - Format markdown content

### Using Plugins

Plugins are automatically loaded and available to agents:

```yaml
agents:
  agent1:
    model: "gpt-4"
    plugins:
      - web_search
      - markdown_formatter
```

## ğŸ”— MCP Integration

Connect to Model Context Protocol servers for extended tool access:

```yaml
mcp_servers:
  filesystem:
    command: "npx"
    args: ["-y", "@modelcontextprotocol/server-filesystem", "/path/to/dir"]
    enabled: true
    
  github:
    command: "npx"
    args: ["-y", "@modelcontextprotocol/server-github"]
    enabled: true
    env:
      GITHUB_TOKEN: "${GITHUB_TOKEN}"
```

List MCP servers and tools:

```bash
weave mcp --list
weave mcp --server-tools filesystem
```

## ğŸ“– Commands

### Core Commands

- `weave init` - Initialize new project
- `weave run` - Interactive agentic chat
- `weave plan` - Preview execution plan
- `weave apply` - Execute workflow

### Development

- `weave dev --watch` - Development mode with auto-reload
- `weave state --list` - List execution runs
- `weave inspect <run-id>` - Inspect run details

### Tools & Plugins

- `weave tools` - List available tools
- `weave tools --schema <tool-name>` - View tool schema
- `weave plugins` - List plugins
- `weave mcp` - Manage MCP servers

## ğŸ“‚ Configuration

### Agent Definition

```yaml
agents:
  agent_name:
    model: "model-name"              # Required
    tools: [tool1, tool2]            # Optional
    plugins: [plugin1]               # Optional
    inputs: "other_agent"            # Optional: dependency
    outputs: "output_key"            # Optional: output name
    model_config:                    # Optional: LLM config
      temperature: 0.7
      max_tokens: 1000
    memory:                          # Optional: conversation memory
      type: "buffer"
      max_messages: 100
    storage:                         # Optional: output storage
      save_outputs: true
```

### Custom Tools

```yaml
tools:
  custom_tool:
    description: "My custom tool"
    category: "custom"
    parameters:
      param1:
        type: "string"
        description: "Parameter description"
        required: true
```

## ğŸ“Š Resource Management

Organize agent resources in `.agent/` directory:

```
.agent/
â”œâ”€â”€ prompts/         # System prompts (YAML + markdown)
â”œâ”€â”€ skills/          # Agent skills (YAML)
â”œâ”€â”€ recipes/         # Workflow templates
â”œâ”€â”€ knowledge/       # Knowledge bases
â”œâ”€â”€ rules/           # Agent constraints
â”œâ”€â”€ behaviors/       # Behavioral guidelines
â””â”€â”€ sub_agents/      # Nested agents
```

Create resource structure:

```bash
weave resources --create
```

## ğŸ“‚ Examples

Complete examples with resources:

- **[coding-agent-example/](examples/coding-agent-example/)** - Software development
- **[content-creation-example/](examples/content-creation-example/)** - Blog posts
- **[research-assistant-example/](examples/research-assistant-example/)** - Research & analysis
- **[customer-support-example/](examples/customer-support-example/)** - Support automation

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       CLI Layer (Typer)         â”‚
â”‚  Commands: init, plan, apply    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Parser Layer (PyYAML)        â”‚
â”‚  YAML loading + env substitutionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Core Layer (Pydantic+NetworkX) â”‚
â”‚  Validation + dependency graph  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Executor (Real LLMs)        â”‚
â”‚  OpenAI + Anthropic + Tools     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

- **CLI** (`src/weave/cli/`) - Typer commands with Rich output
- **Parser** (`src/weave/parser/`) - YAML parsing and env substitution
- **Core** (`src/weave/core/`) - Pydantic models and dependency graph
- **Executor** (`src/weave/runtime/`) - Real LLM execution
- **Tools** (`src/weave/tools/`) - Tool calling system + MCP
- **Plugins** (`src/weave/plugins/`) - Plugin system


